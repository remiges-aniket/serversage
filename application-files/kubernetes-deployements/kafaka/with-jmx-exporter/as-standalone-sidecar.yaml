apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-kraft-config
  namespace: kafka
  labels:
    app.kubernetes.io/name: kafka-kraft-config
data:
  server.properties: |
    # Enable KRaft mode
    kraft.enabled=true
    
    # Basic Broker Settings
    broker.id=BROKER_ID_PLACEHOLDER
    node.id=NODE_ID_PLACEHOLDER
    process.roles=broker,controller
    
    # Listeners
    listeners=PLAINTEXT://:9092,CONTROLLER://:9093
    advertised.listeners=PLAINTEXT://POD_NAME_PLACEHOLDER.kafka-headless.NAMESPACE_PLACEHOLDER.svc.cluster.local:9092
    # advertised.listeners=PLAINTEXT://kafka-headless.NAMESPACE_PLACEHOLDER.svc.cluster.local:9092
    
    # Controller configuration
    controller.quorum.voters=CONTROLLER_QUORUM_VOTERS_PLACEHOLDER
    controller.listener.names=CONTROLLER
    
    # Networking
    inter.broker.listener.name=PLAINTEXT
    listener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
    num.network.threads=3
    num.io.threads=8
    socket.send.buffer.bytes=102400
    socket.receive.buffer.bytes=102400
    socket.request.max.bytes=104857600
    
    # Data Storage
    log.dirs=/var/lib/kafka/data
    
    # Topic defaults
    num.partitions=1
    num.recovery.threads.per.data.dir=1
    offsets.topic.replication.factor=3
    transaction.state.log.replication.factor=3
    transaction.state.log.min.isr=2
    min.insync.replicas=2
    
    # Log retention
    log.retention.hours=48
    log.segment.bytes=1073741824
    log.retention.check.interval.ms=300000
---
# JMX Exporter ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-jmx-exporter-config
  namespace: kafka
data:
  kafka-jmx-config.yml: |
    hostPort: localhost:5555
    startDelaySeconds: 30
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    rules:
    # Special cases and very specific rules
    - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)><>Value
      name: kafka_server_$1_$2
      type: GAUGE
      labels:
        clientId: "$3"
        topic: "$4"
        partition: "$5"
    - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), brokerHost=(.+), brokerPort=(.+)><>Value
      name: kafka_server_$1_$2
      type: GAUGE
      labels:
        clientId: "$3"
        broker: "$4:$5"
    
    # Generic per-topic metrics
    - pattern: kafka.server<type=(.+), name=(.+), topic=(.+)><>Value
      name: kafka_server_$1_$2
      type: GAUGE
      labels:
        topic: "$3"
    
    # Generic broker metrics
    - pattern: kafka.server<type=(.+), name=(.+)><>Value
      name: kafka_server_$1_$2
      type: GAUGE
    
    # Controller metrics
    - pattern: kafka.controller<type=(.+), name=(.+)><>Value
      name: kafka_controller_$1_$2
      type: GAUGE
    
    # Kafka metrics
    - pattern: kafka.(\w+)<type=(.+), name=(.+)><>(\w+)
      name: kafka_$1_$2_$3_$4
      type: GAUGE

    # Generic JVM metrics
    - pattern: java.lang<type=Memory><(.+)>(.+)
      name: jvm_memory_$1
      type: GAUGE
    
    - pattern: java.lang<type=GarbageCollector, name=(.+)><>CollectionCount
      name: jvm_gc_collection_total
      labels:
        collector: "$1"
      type: COUNTER
    
    - pattern: java.lang<type=GarbageCollector, name=(.+)><>CollectionTime
      name: jvm_gc_collection_time_ms
      labels:
        collector: "$1"
      type: COUNTER
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: kafka
spec:
  serviceName: kafka-headless
  podManagementPolicy: Parallel
  replicas: 1
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      terminationGracePeriodSeconds: 30
      securityContext:
        fsGroup: 1000
      initContainers:
      - name: volume-permission-fix
        image: busybox:1.37.0
        command: ["sh", "-c", "chown -R 1000:1000 /var/lib/kafka/data"]
        volumeMounts:
          - name: data
            mountPath: /var/lib/kafka/data
      - name: wait-for-dns
        image: busybox:1.37.0
        imagePullPolicy: "IfNotPresent" 
        command:
        - /bin/sh
        - -c
        - |
          set -e
          echo "Checking DNS resolution..."
          # Try to resolve our own hostname first
          getent hosts $HOSTNAME.kafka-headless.$NAMESPACE.svc.cluster.local || echo "Warning: Can't resolve own hostname yet"
          # getent hosts kafka-headless.$NAMESPACE.svc.cluster.local || echo "Warning: Can't resolve own hostname yet"
          echo "DNS check completed"
        env:
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
      containers:
      - name: kafka
        image: bitnami/kafka:4.0.0
        imagePullPolicy: "IfNotPresent"
        securityContext:
          runAsUser: 1000
        ports:
        - containerPort: 9092
          name: plaintext
        - containerPort: 9093
          name: controller
        - containerPort: 5555
          name: jmx
        env:
        - name: KAFKA_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: KAFKA_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: KAFKA_CLUSTER_ID
          value: "MkU3OEVBNTcwNTJENDM2Qg"
        - name: KAFKA_HEAP_OPTS
          value: "-Xmx1G -Xms1G"
        - name: KAFKA_OPTS
          value: "-Dkraft.enabled=true -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=127.0.0.1 -Dcom.sun.management.jmxremote.host=127.0.0.1 -Dcom.sun.management.jmxremote.port=5555 -Dcom.sun.management.jmxremote.rmi.port=5555"
        # - name: JMX_PORT
        #   value: ""
        command:
        - /bin/bash
        - -c
        - |
          # Wait a bit for DNS propagation 
          sleep 10
          
          # Set the broker.id based on StatefulSet pod ordinal index
          ORDINAL=$(echo $KAFKA_POD_NAME | rev | cut -d'-' -f1 | rev)
          
          # Construct the controller quorum voters
          # CONTROLLER_QUORUM_VOTERS="0@kafka-0.kafka-headless.${KAFKA_NAMESPACE}.svc.cluster.local:9093,1@kafka-1.kafka-headless.${KAFKA_NAMESPACE}.svc.cluster.local:9093"
          CONTROLLER_QUORUM_VOTERS="0@kafka-0.kafka-headless.${KAFKA_NAMESPACE}.svc.cluster.local:9093"
          
          echo "Starting Kafka with broker.id=$ORDINAL"
          echo "Controller quorum voters: $CONTROLLER_QUORUM_VOTERS"
          
          # Copy and update the config file with manual sed instead of envsubst
          cp /config/server.properties /tmp/server.properties
          
          # Replace placeholders with actual values
          sed -i "s/BROKER_ID_PLACEHOLDER/$ORDINAL/" /tmp/server.properties
          sed -i "s/NODE_ID_PLACEHOLDER/$ORDINAL/" /tmp/server.properties
          sed -i "s/POD_NAME_PLACEHOLDER/$KAFKA_POD_NAME/" /tmp/server.properties
          sed -i "s/NAMESPACE_PLACEHOLDER/$KAFKA_NAMESPACE/" /tmp/server.properties
          sed -i "s/CONTROLLER_QUORUM_VOTERS_PLACEHOLDER/$CONTROLLER_QUORUM_VOTERS/" /tmp/server.properties
          
          # Check for existing metadata or format storage
          if [ ! -f "/var/lib/kafka/data/meta.properties" ]; then
            echo "Formatting Kafka storage..."
            /opt/bitnami/kafka/bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c /tmp/server.properties
          else
            echo "Metadata already exists, skipping format"
          fi
          
          # Start Kafka with KRaft mode explicitly
          exec /opt/bitnami/kafka/bin/kafka-server-start.sh /tmp/server.properties
        volumeMounts:
        - name: data
          mountPath: /var/lib/kafka/data
        - name: config
          mountPath: /config
        resources:
          requests:
            memory: "2Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
      # JMX Exporter sidecar container
      - name: jmx-exporter
        image: bitnami/jmx-exporter:latest
        imagePullPolicy: "IfNotPresent"
        ports:
        - containerPort: 9404
          name: jmx-metrics
        args:
        - "9404"
        - "/etc/jmx-exporter/kafka-jmx-config.yml"
        volumeMounts:
        - name: jmx-config
          mountPath: /etc/jmx-exporter
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
      volumes:
      - name: config
        configMap:
          name: kafka-kraft-config
      - name: jmx-config
        configMap:
          name: kafka-jmx-exporter-config
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 3Gi
---
apiVersion: v1
kind: Service
metadata:
  name: kafka-headless
  namespace: kafka
spec:
  clusterIP: None
  publishNotReadyAddresses: true
  selector:
    app: kafka
  ports:
  - port: 9092
    name: plaintext
  - port: 9093
    name: controller
  - port: 9404
    name: jmx-metrics
---
apiVersion: v1
kind: Service
metadata:
  name: kafka
  namespace: kafka
spec:
  selector:
    app: kafka
  ports:
  - port: 9092
    targetPort: 9092
    name: plaintext
---
# Service for JMX exporter metrics
apiVersion: v1
kind: Service
metadata:
  name: kafka-metrics
  namespace: kafka
  labels:
    app: kafka
    service: metrics
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9404"
spec:
  selector:
    app: kafka
  ports:
  - port: 9404
    targetPort: 9404
    name: jmx-metrics
  type: ClusterIP